# Image-to-LaTeX

Deep learning pipeline for converting handwritten mathematical expressions to LaTeX.

## Architecture

- **Encoder**: CNN backbone (ResNet) + 2D positional encoding + Transformer encoder
- **Decoder**: Autoregressive Transformer decoder with cross-attention

## Datasets

| Dataset | Type | Samples | Format |
|---------|------|---------|--------|
| PRINTED_TEX_230k | Printed | ~235k | PNG images |
| HME100K | Handwritten | ~99k | JPG images |
| MathWriting-2024 | Handwritten | ~649k | InkML → PNG |
| CROHME | Handwritten | ~13k | InkML → PNG |

## Setup

```bash
pip install -r requirements.txt
```

## Data Preparation

### 1. Download Datasets

Download the following datasets and place them in your data directory (default: `/Data/img-to-latex/`).

- **im2latex 230k** (Printed):
  - [Zenodo Link](https://zenodo.org/records/7738969)
  - Extract to: `PRINTED_TEX_230k/`

- **CROHME & HME100K** (Handwritten):
  - [Figshare Link](https://doi.org/10.6084/m9.figshare.30341779.v1)
  - Extract HME100K to: `HME100K/`
  - Extract CROHME to: `TC11_package/` (should contain `CROHME2016_data`, etc.)

- **MathWriting** (Handwritten):
  - [Google Storage Link](https://storage.googleapis.com/mathwriting_data/mathwriting-2024.tgz)
  - Extract to: `mathwriting-2024/`

### 2. Extract & Process Data

Run the following scripts to prepare the data for training. You can specify your custom data directory using the `--data-dir` argument (default is `/Data/img-to-latex`).

1. **Extract CROHME sub-archives:**
   The CROHME dataset comes with internal zip files that need to be extracted.
   ```bash
   python scripts/extract_crohme.py --data-dir /path/to/your/data
   ```

2. **Convert InkML to Images:**
   Convert the online handwritten datasets (MathWriting, CROHME) from InkML to PNG images.
   ```bash
   python scripts/inkml_to_image.py --dataset all --data-dir /path/to/your/data
   ```
   *This will create a `converted/` directory containing the processed images inside your data directory.*

3. **Build Vocabulary:**
   Create the tokenizer vocabulary from all available datasets.
   ```bash
   python scripts/build_vocab.py --data-dir /path/to/your/data --base-vocab /path/to/your/data/PRINTED_TEX_230k/230k.json
   ```

### Expected Directory Structure
After preparation, your data directory should look like this:

```
/path/to/your/data/
├── PRINTED_TEX_230k/    # From im2latex 230k
├── HME100K/             # From HME100K
├── TC11_package/        # From CROHME (with extracted sub-folders)
├── mathwriting-2024/    # From MathWriting
├── converted/           # Generated by inkml_to_image.py
│   ├── crohme/
│   └── mathwriting/
└── vocab.json           # Generated by build_vocab.py
```

## Training

### Pretraining
Train the model on the large printed dataset (im2latex 230k) to learn LaTeX syntax and structure.

```bash
python scripts/train.py --config configs/pretrain.yaml
```

### Fine-tuning
Fine-tune the pretrained model on handwritten datasets (MathWriting, CROHME, HME100K).

```bash
python scripts/train.py --config configs/finetune.yaml --resume checkpoints/pretrain/best.pt
```

### Common Training Options
- **Resume Training:** Continue from a specific checkpoint (restores optimizer state and scheduler).
  ```bash
  python scripts/train.py --config configs/pretrain.yaml --resume checkpoints/pretrain/latest.pt
  ```
- **Debug Mode:** Train on a small fraction of data to check pipeline.
  ```bash
  python scripts/train.py --config configs/pretrain.yaml --data-fraction 0.01
  ```
- **Device:** Specify compute device (default: cuda if available).
  ```bash
  python scripts/train.py --config configs/pretrain.yaml --device cpu
  ```

**Logging:** Training progress (loss, accuracy, BLEU) is logged to TensorBoard.
```bash
tensorboard --logdir logs/
```

## Evaluation

Evaluate the model's performance using metrics like Token Accuracy, Sequence Accuracy, and BLEU score.

### Basic Evaluation
```bash
python scripts/evaluate.py --config configs/finetune.yaml --checkpoint checkpoints/finetune/best.pt
```

### Advanced Options
- **Beam Search:** Use beam search for better generation quality (slower).
  ```bash
  python scripts/evaluate.py --config configs/finetune.yaml --checkpoint checkpoints/finetune/best.pt --beam-size 5
  ```
- **Save Predictions:** Output predictions to a file for analysis.
  ```bash
  python scripts/evaluate.py ... --output predictions.tsv
  ```
- **Test Specific Split:** Evaluate on validation or test sets.
  ```bash
  python scripts/evaluate.py ... --split valid
  ```

## Project Structure

```
img-to-latex/
├── configs/           # YAML configuration files (hyperparameters)
├── scripts/           # CLI entry points
│   ├── train.py           # Main training loop
│   ├── evaluate.py        # Evaluation and metric calculation
│   ├── build_vocab.py     # Vocabulary generation
│   ├── inkml_to_image.py  # Data preprocessing
│   └── extract_crohme.py  # Data preprocessing
└── src/
    ├── data/          # Data loading logic
    │   ├── tokenizer.py   # Tokenizer implementation
    │   └── ...            # Dataset specific loaders
    ├── models/        # Model architecture
    │   ├── encoder.py     # ResNet + Transformer Encoder
    │   └── decoder.py     # Transformer Decoder
    ├── training/      # Training components
    │   ├── trainer.py     # Training loop manager
    │   └── metrics.py     # BLEU/Accuracy calculation
    └── utils/         # Utilities
```

## Extending the Project

### Adding New Datasets
1. Create a new dataset class in `src/data/` inheriting from `BaseDataset`.
2. Implement `_load_data()` to return a list of `(image_path, latex_label)` tuples.
3. Register the new dataset in `src/data/combined.py`.
4. Update your config YAML to include the new dataset name.

### Adding New Models
1. Create a model class in `src/models/` with the same interface as `Img2LaTeX`.
2. Implement `forward()`, `get_loss()`, and `generate()` methods.
3. Update `src/models/__init__.py` to export it.
4. Create a new config file in `configs/` pointing to your new architecture.

